name: Google Compute Engine Create
on:
  workflow_dispatch:
    inputs:
      window-step:
        description: 'step size used for sliding window data splitter'
        required: true
        default: 20
      down-sampling-factor:
        description: 'factor by which target classes are capped in comparison to smallest class'
        required: true
        default: 3.0
      model:
        description: 'model to use for training'
        required: true
        default: 'cnn'
      k-folds:
        description: 'number of k-folds'
        required: true
        default: 10
      epochs:
        description: 'number of epochs'
        required: true
        default: 5000
      learning-rate:
        description: 'learning rate'
        required: true
        default: 0.001
      patience:
        description: 'number of epochs to wait for improvements before finishing training'
        required: true
        default: 500
      slice-width:
        description: 'number of measurements per slice'
        required: true
        default: 500
      lstm-hidden-dimension:
        description: 'hidden dimensions in LSTM'
        required: true
        default: 128
      lstm-layer-dimension:
        description: 'layer dimensions in LSTM'
        required: true
        default: 3
env:
  PROJECT_ID: "bike-path-quality"
  GCE_INSTANCE: "bike-path-quality-analytics"
  GCE_INSTANCE_ZONE: "europe-west2-a"
  GCE_SERVICE_ACCOUNT: "bike-path-quality-analytics@bike-path-quality.iam.gserviceaccount.com"
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.7]
    steps:
      - name: Checkout
        uses: actions/checkout@v2.3.3
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: "bike-path-quality"
          service_account_key: ${{ secrets.GOOGLE_CLOUD_TOKEN }}
          export_default_credentials: true
        env:
          GOOGLE_CLOUD_TOKEN: ${{ secrets.GOOGLE_CLOUD_TOKEN }}
      - name: Prepare Google Cloud service account token
        id: prepare-google-cloud-service-account-token
        run: echo $GOOGLE_CLOUD_TOKEN | base64 --decode > ./bike-path-quality-2bebc8ae5dc6.json
        env:
          GOOGLE_CLOUD_TOKEN: ${{ secrets.GOOGLE_CLOUD_TOKEN }}
      - name: Create startup script
        id: create-startup-script
        run: |
          echo "#! /bin/bash" >> startup.sh
          echo "sleep 300" >> startup.sh
          echo "sudo apt-get install python3-venv -y >> log.txt" >> startup.sh
          echo "sudo useradd -m -s /bin/bash training >> log.txt" >> startup.sh
          echo "sudo -u training bash -c \"mkdir -p ~/.ssh; ssh-keyscan github.com >> ~/.ssh/known_hosts\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~; git clone https://github.com/fom-big-data-bike-path-quality/fom-big-data-bike-path-quality-analytics.git\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~; git clone https://github.com/fom-big-data-bike-path-quality/fom-big-data-bike-path-quality-data.git fom-big-data-bike-path-quality-analytics/data\"" >> startup.sh
          echo "sudo -u training bash -c \"gsutil cp gs://bike-path-quality-analytics/telegram.config ~/fom-big-data-bike-path-quality-analytics/lib/log/\"" >> startup.sh
          echo "sudo -u training bash -c \"gsutil cp gs://bike-path-quality-analytics/bike-path-quality-2bebc8ae5dc6.json ~/fom-big-data-bike-path-quality-analytics/lib/cloud/\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; rm -rf data/data/measurements/csv\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; rm -rf data/data/measurements/geojson\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; rm -rf data/data/measurements/json\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install flake8 pytest >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install pandas >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install matplotlib >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install sklearn >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install torch >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install tqdm >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install seaborn >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install telegram-send >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install gcloud >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install google-api-core >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install google-auth >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install google-cloud-core >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install google-cloud-storage >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; pip3 install dtaidistance >> log.txt\"" >> startup.sh
          echo "sudo -u training bash -c \"cd ~/fom-big-data-bike-path-quality-analytics; nohup python3 main.py --clean --window-step=${{ github.event.inputs.window-step }} --down-sampling-factor=${{ github.event.inputs.down-sampling-factor }} --model=${{ github.event.inputs.model }} --k-folds=${{ github.event.inputs.k-folds }} --epochs=${{ github.event.inputs.epochs }} --learning-rate=${{ github.event.inputs.learning-rate }} --patience=${{ github.event.inputs.patience }} --slice-width=${{ github.event.inputs.slice-width }} --lstm-hidden-dimension=${{ github.event.inputs.lstm-hidden-dimension }} --lstm-layer-dimension=${{ github.event.inputs.lstm-layer-dimension }} 2>&1 >> log.txt &\"" >> startup.sh
      - name: Create compute instance
        id: create-compute-instance
        run: |
          gcloud compute instances create "$GCE_INSTANCE" \
            --zone="$GCE_INSTANCE_ZONE" \
            --machine-type=n1-standard-8 \
            --image-family=pytorch-latest-gpu \
            --image-project=deeplearning-platform-release \
            --maintenance-policy=TERMINATE \
            --accelerator="type=nvidia-tesla-t4,count=1" \
            --service-account="$GCE_SERVICE_ACCOUNT" \
            --scopes="https://www.googleapis.com/auth/cloud-platform" \
            --metadata-from-file=startup-script="startup.sh" \
            --metadata="install-nvidia-driver=True"
